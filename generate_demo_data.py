#!/usr/bin/env python3
"""
Eponaè‡ªå®šä¹‰æµ‹è¯•æ•°æ®ç”Ÿæˆè„šæœ¬
è‡ªåŠ¨ç”Ÿæˆæ¨¡æ‹Ÿçš„é©¾é©¶åœºæ™¯æ•°æ®ç”¨äºæµ‹è¯•
"""

import os
import argparse
import numpy as np
import cv2
from pathlib import Path


def create_synthetic_frame(frame_idx, scenario='straight', size=(512, 1024)):
    """
    åˆ›å»ºåˆæˆæµ‹è¯•å›¾åƒ
    
    Args:
        frame_idx: å¸§ç´¢å¼•
        scenario: åœºæ™¯ç±»å‹ ('straight', 'left_turn', 'right_turn')
        size: å›¾åƒå¤§å° (height, width)
    """
    h, w = size
    img = np.zeros((h, w, 3), dtype=np.uint8)
    
    # å¤©ç©ºèƒŒæ™¯
    img[:h//2, :] = [135, 206, 235]  # å¤©è“è‰²
    
    # åœ°é¢
    img[h//2:, :] = [100, 100, 100]  # ç°è‰²
    
    # ç»˜åˆ¶é“è·¯
    road_left = w//4
    road_right = 3*w//4
    
    if scenario == 'left_turn':
        # å·¦è½¬:é“è·¯é€æ¸å‘å·¦åç§»
        offset = int(frame_idx * w / 40)
        road_left -= offset
        road_right -= offset
    elif scenario == 'right_turn':
        # å³è½¬:é“è·¯é€æ¸å‘å³åç§» 
        offset = int(frame_idx * w / 40)
        road_left += offset
        road_right += offset
    
    cv2.rectangle(img, (max(0, road_left), h//2), 
                  (min(w, road_right), h), (50, 50, 50), -1)
    
    # ç»˜åˆ¶è½¦é“çº¿(åŠ¨ç”»æ•ˆæœ)
    lane_spacing = 50
    lane_offset = (frame_idx * 10) % (lane_spacing * 2)
    
    for i in range(-lane_offset, h, lane_spacing):
        y1 = h//2 + i
        y2 = y1 + lane_spacing//2
        if y1 < h and y2 < h:
            cv2.line(img, (w//2-2, y1), (w//2+2, min(y2, h-1)), 
                    (255, 255, 255), 3)
    
    # ç»˜åˆ¶å·¦å³è·¯è¾¹çº¿
    cv2.line(img, (max(0, road_left), h//2), 
            (max(0, road_left), h), (255, 255, 0), 3)
    cv2.line(img, (min(w, road_right), h//2), 
            (min(w, road_right), h), (255, 255, 0), 3)
    
    # æ·»åŠ å¸§ç¼–å·å’Œåœºæ™¯ä¿¡æ¯
    scenario_text = scenario.replace('_', ' ').title()
    cv2.putText(img, f"Frame {frame_idx:02d} - {scenario_text}", 
                (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
    
    return img


def generate_trajectory_straight(num_frames):
    """ç”Ÿæˆç›´çº¿è¡Œé©¶è½¨è¿¹"""
    poses = []
    yaws = []
    
    for i in range(num_frames):
        # åŒ€é€Ÿç›´è¡Œ,æ¯å¸§å‰è¿›1ç±³
        poses.append([1.0, 0.0])
        yaws.append([0.0])
    
    return np.array([poses]), np.array([yaws])


def generate_trajectory_left_turn(num_frames):
    """ç”Ÿæˆå·¦è½¬å¼¯è½¨è¿¹"""
    poses = []
    yaws = []
    
    for i in range(num_frames):
        t = i / num_frames
        
        # é€æ¸å‡é€Ÿå¹¶å‘å·¦åç§»
        dx = 1.0 - 0.4 * t          # å‰è¿›é€Ÿåº¦å‡ç¼“
        dy = -0.08 * t * t          # å‘å·¦åç§»(yä¸ºè´Ÿ)
        yaw_angle = 2.0 + 4.0 * t   # å·¦è½¬è§’åº¦é€æ¸å¢åŠ 
        
        poses.append([dx, dy])
        yaws.append([yaw_angle])
    
    return np.array([poses]), np.array([yaws])


def generate_trajectory_right_turn(num_frames):
    """ç”Ÿæˆå³è½¬å¼¯è½¨è¿¹"""
    poses = []
    yaws = []
    
    for i in range(num_frames):
        t = i / num_frames
        
        # é€æ¸å‡é€Ÿå¹¶å‘å³åç§»
        dx = 1.0 - 0.3 * t          # å‰è¿›é€Ÿåº¦å‡ç¼“
        dy = 0.08 * t * t           # å‘å³åç§»(yä¸ºæ­£)
        yaw_angle = -2.0 - 3.0 * t  # å³è½¬è§’åº¦é€æ¸å¢åŠ (è´Ÿå€¼)
        
        poses.append([dx, dy])
        yaws.append([yaw_angle])
    
    return np.array([poses]), np.array([yaws])


def generate_video_data(output_dir, video_name, scenario='straight', 
                       num_frames=10, image_size=(512, 1024)):
    """
    ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„æµ‹è¯•è§†é¢‘æ•°æ®
    
    Args:
        output_dir: è¾“å‡ºç›®å½•
        video_name: è§†é¢‘åç§°
        scenario: åœºæ™¯ç±»å‹ ('straight', 'left_turn', 'right_turn')
        num_frames: å¸§æ•°
        image_size: å›¾åƒå¤§å°
    """
    video_dir = Path(output_dir) / video_name
    video_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"ç”Ÿæˆè§†é¢‘: {video_name} ({scenario}, {num_frames}å¸§)")
    
    # 1. ç”Ÿæˆå›¾åƒ
    for i in range(num_frames):
        img = create_synthetic_frame(i, scenario, image_size)
        img_path = video_dir / f"{i:06d}.png"
        cv2.imwrite(str(img_path), img)
    
    # 2. ç”Ÿæˆè½¨è¿¹æ•°æ®
    if scenario == 'straight':
        pose, yaw = generate_trajectory_straight(num_frames + 1)
    elif scenario == 'left_turn':
        pose, yaw = generate_trajectory_left_turn(num_frames + 1)
    elif scenario == 'right_turn':
        pose, yaw = generate_trajectory_right_turn(num_frames + 1)
    else:
        raise ValueError(f"Unknown scenario: {scenario}")
        raise ValueError(f"Unknown scenario: {scenario}")
    
    # 3. ä¿å­˜numpyæ–‡ä»¶
    np.save(video_dir / 'pose.npy', pose)
    np.save(video_dir / 'yaw.npy', yaw)
    
    # 4. éªŒè¯æ•°æ®
    print(f"  âœ… ç”Ÿæˆ {num_frames} å¸§å›¾åƒ")
    print(f"  âœ… pose shape: {pose.shape}")
    print(f"  âœ… yaw shape: {yaw.shape}")
    print(f"  ğŸ“ ä¿å­˜åˆ°: {video_dir}")
    
    return video_dir


def main():
    parser = argparse.ArgumentParser(description='ç”ŸæˆEponaæµ‹è¯•æ•°æ®')
    parser.add_argument('--output_dir', type=str, default='data',
                       help='è¾“å‡ºç›®å½• (default: data)')
    parser.add_argument('--num_videos', type=int, default=3,
                       help='ç”Ÿæˆè§†é¢‘æ•°é‡ (default: 3)')
    parser.add_argument('--num_frames', type=int, default=10,
                       help='æ¯ä¸ªè§†é¢‘çš„å¸§æ•° (default: 10)')
    parser.add_argument('--image_size', type=str, default='512x1024',
                       help='å›¾åƒå¤§å° HxW (default: 512x1024)')
    
    args = parser.parse_args()
    
    # è§£æå›¾åƒå¤§å°
    h, w = map(int, args.image_size.split('x'))
    image_size = (h, w)
    
    print("="*60)
    print("Epona è‡ªå®šä¹‰æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨")
    print("="*60)
    print(f"è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"è§†é¢‘æ•°é‡: {args.num_videos}")
    print(f"æ¯è§†é¢‘å¸§æ•°: {args.num_frames}")
    print(f"å›¾åƒå¤§å°: {h}x{w}")
    print("="*60 + "\n")
    
    # åœºæ™¯åˆ—è¡¨
    scenarios = ['straight', 'left_turn', 'right_turn']
    
    # ç”Ÿæˆå¤šä¸ªè§†é¢‘
    for i in range(args.num_videos):
        scenario = scenarios[i % len(scenarios)]
        video_name = f"video-{i+1:02d}"
        
        generate_video_data(
            output_dir=args.output_dir,
            video_name=video_name,
            scenario=scenario,
            num_frames=args.num_frames,
            image_size=image_size
        )
        print()
    
    print("="*60)
    print(f"âœ… æˆåŠŸç”Ÿæˆ {args.num_videos} ä¸ªæµ‹è¯•è§†é¢‘!")
    print("="*60)
    print("\nä¸‹ä¸€æ­¥:")
    print(f"1. æŸ¥çœ‹ç”Ÿæˆçš„æ•°æ®: ls -lh {args.output_dir}/*/")
    print("2. è¿è¡Œæµ‹è¯•è„šæœ¬:")
    print("   python scripts/test/test_demo.py ")
    print("       --exp_name 'demo_test' ")
    print("       --resume_path 'pretrained/epona_nuplan.pkl' ")
    print("       --config 'configs/dit_config_dcae_nuplan_cached.py'")
    print()


if __name__ == '__main__':
    main()
